# Ruff Language - Development Roadmap

This roadmap outlines **upcoming** planned features and improvements. For completed features and bug fixes, see [CHANGELOG.md](CHANGELOG.md).

> **Current Version**: v0.8.0 (Released January 2026)  
> **Next Planned Release**: v0.9.0 (VM Integration & Performance)  
> **Status**: üöß In Progress - JIT Compilation Phase 3 ~75% Complete! (Jan 2026)

---

## üéØ What's Next (Priority Order)

**IMMEDIATE NEXT**:
1. **Complete JIT Execution** - Execute compiled native code, not just cache it (Week 5-6)
2. **Advanced JIT Optimizations** - Type specialization, inline caching, escape analysis (Weeks 7-8)

**AFTER THAT**:
3. **Performance Benchmarking** - Comprehensive performance analysis and tuning (Week 9-10)
4. **True Async Runtime** - Tokio integration for concurrent I/O (Phase 5, P2 priority)
5. **Architecture Cleanup** - Fix LeakyFunctionBody, separate AST from runtime values (P2, non-blocking)

---

## Priority Levels

- **P1 (High)**: Core features needed for v1.0 production readiness
- **P2 (Medium)**: Quality-of-life improvements and developer experience
- **P3 (Low)**: Nice-to-have features for advanced use cases

---

## v0.9.0 - VM Integration & Performance (IN PROGRESS)

**Focus**: Complete bytecode VM integration and achieve near-native performance  
**Timeline**: Q1-Q2 2026 (3-4 months total)  
**Priority**: P1 - Essential for v1.0

> **Progress**: ‚úÖ Exception handling complete | ‚úÖ Generators complete | ‚úÖ Async/await complete | ‚úÖ Integration complete | ‚úÖ Phase 2 optimizations complete | üéØ JIT compilation next

---

### 28. Complete VM Integration + JIT Compilation (P1)

**Status**: ~85% Complete  
**Estimated Effort**: Very Large (3-4 months total)

**Why Critical**: To compete with Go and other modern languages, Ruff needs near-native performance. Tree-walking interpreters are 100-500x slower than compiled languages. This is essential for v1.0 adoption.

**Performance Targets**:
- Current (tree-walking): ~100-500x slower than Go
- After bytecode VM: ~10-50x slower than Go  
- After JIT compilation: ~2-10x slower than Go
- Goal: Performance competitive with Go for I/O-bound workloads

**Completed So Far**:
- ‚úÖ VM instruction set design (60+ opcodes)
- ‚úÖ Bytecode compiler for all AST nodes
- ‚úÖ Function calls, closures, upvalues
- ‚úÖ Exception handling with proper unwinding (BeginTry/EndTry/Throw/BeginCatch/EndCatch)
- ‚úÖ Generator support (MakeGenerator/Yield/ResumeGenerator with full instruction dispatch)
- ‚úÖ Async/await support (Await/MakePromise opcodes with Promise wrapping)
- ‚úÖ Native function integration (180+ functions)

**Remaining Work**:
- Phase 1: VM Integration & Testing (2 weeks)
- Phase 2: Basic Optimizations (2-3 weeks)
- Phase 3: JIT Compilation Infrastructure (4-6 weeks)
- Phase 4: Advanced JIT Optimizations (2-3 weeks)
- Phase 5: True Async Runtime Integration with Tokio (2-3 weeks) - Optional, P2 priority
- Phase 6: Benchmarking & Tuning (1-2 weeks)

---

#### Phase 1: Complete Bytecode VM Integration (6-8 weeks) - ‚úÖ COMPLETE

**Status**: 100% Complete (exception handling ‚úÖ, generators ‚úÖ, async/await ‚úÖ, integration ‚úÖ)

**‚úÖ Completed: Week 5-6 - Async/Await Support**
  
- [x] Implement Await opcode (suspend until promise resolves) ‚úÖ
- [x] Implement MakePromise opcode (wrap value in promise) ‚úÖ
- [x] Add promise state management to VM ‚úÖ
- [x] Test with existing async examples ‚úÖ
- [x] Add comprehensive async/await tests (7 tests) ‚úÖ
- Note: Async runtime integration deferred - VM executes async synchronously (sufficient for now)

**‚úÖ Completed: Week 7-8 - Integration & Testing**
  
- [x] Switch default execution mode to VM ‚úÖ
- [x] Add `--interpreter` flag for fallback mode ‚úÖ
- [x] Run full test suite in VM mode (198+ tests) ‚úÖ
- [x] Performance benchmarking baseline ‚úÖ
- [x] Document performance characteristics ‚úÖ

**Performance Baseline**: VM executes correctly with full feature parity. Current performance is baseline (unoptimized). Phase 2 will add optimizations for 2-3x improvement.

---

#### Phase 2: Basic Optimizations (2-3 weeks) - ‚úÖ COMPLETE

**Status**: 100% Complete (January 2026)

**Completed Work**:
- ‚úÖ **Constant Folding**: Compile-time evaluation of constant expressions
  - Arithmetic operations (int, float, mixed)
  - Boolean operations (&&, ||, !)
  - String concatenation
  - Comparison operations
  - Safely skips division by zero
- ‚úÖ **Dead Code Elimination**: Removes unreachable instructions
  - Code after return/throw statements
  - Unreachable branches
  - Updates jump targets and exception handlers
- ‚úÖ **Peephole Optimizations**: Small pattern replacements
  - Redundant LoadConst + Pop elimination
  - Double jump elimination
  - StoreVar + LoadVar optimization
- ‚úÖ **Integration**: Automatic optimization during compilation
- ‚úÖ **Testing**: 15 comprehensive test scenarios
- ‚úÖ **Zero Regressions**: All 198 existing tests pass

**Performance Results**:
- Example test file: 19 constants folded, 44 dead instructions removed, 2 peephole optimizations
- Bytecode size reduced by dead code elimination
- Runtime performance improved by pre-computed constants
- Ready for Phase 3 (JIT compilation)

**Files**:
- `src/optimizer.rs` - Optimization pass implementation (650+ lines)
- `tests/test_vm_optimizations.ruff` - Comprehensive test suite
- See CHANGELOG.md for detailed feature descriptions

---

#### Phase 3: JIT Compilation Infrastructure (4-6 weeks) - ‚úÖ 100% COMPLETE!

**Status**: ‚úÖ **100% Complete** (January 2026)  
**Decision**: Using **Cranelift Backend** (lighter weight, faster iteration)

**Completed Work**:
- ‚úÖ **Week 1-2: JIT Infrastructure** (COMPLETE)
  - Hot path detection with execution counters (threshold: 100 iterations)
  - Threshold-based compilation triggers for backward jumps (loops)
  - Code cache management with HashMap storage
  - Graceful degradation (falls back to bytecode interpretation)
  - JIT enable/disable functionality
  - Statistics tracking (functions monitored, compiled, enabled status)

- ‚úÖ **Week 3-4: Bytecode ‚Üí Native Compiler** (COMPLETE)
  - Translate arithmetic bytecode to Cranelift IR (Add, Sub, Mul, Div, Mod, Negate)
  - Translate comparison operations (Equal, NotEqual, LessThan, GreaterThan, LessEqual, GreaterEqual)
  - Translate logical operations (And, Or, Not)
  - Translate stack operations (Pop, Dup)
  - Translate constant loading (Int, Bool)
  - **Control flow translation** (Jump, JumpIfFalse, JumpIfTrue, JumpBack)
  - **Proper basic blocks**: Two-pass translation with pre-created blocks
  - **Block sealing and termination**: Correct handling of control flow edges
  - Return and ReturnNone instructions
  - Generate native machine code via Cranelift
  - Function signature translation (fn(*mut Value) -> i64)
  - **Loop support**: Successfully compiles loops with backward jumps

- ‚úÖ **VM Integration** (COMPLETE)
  - JIT compiler instance added to VM
  - Hot loop detection in execution loop (JumpBack opcodes)
  - Automatic compilation when thresholds reached
  - Debug logging support (DEBUG_JIT environment variable)
  - All 198 tests pass with JIT enabled

- ‚úÖ **Native Code Execution** (COMPLETE - üöÄ HUGE WIN!)
  - **Successfully executing compiled native code via unsafe FFI**
  - **üöÄ Performance Validated: 37,647x speedup for pure arithmetic!**
    - Bytecode VM: ~3.14 seconds for 10,000 iterations of `5 + 3 * 2`
    - JIT compiled: ~83 microseconds for same workload
    - Exceeds performance target (5-10x) by 3,764x!
  - Direct function pointer calls to Cranelift-generated code
  - Return code handling (i64 status codes)
  - Test suite validates execution correctness

- ‚úÖ **Runtime Context & Variable Infrastructure** (COMPLETE)
  - **VMContext structure** created for passing VM state to JIT
  - **Runtime helper functions** implemented:
    - jit_stack_push/pop for stack operations
    - jit_load_variable for reading variables (Int values)
    - jit_store_variable for writing variables
  - **Variable opcodes translation**: LoadVar, StoreVar, LoadGlobal, StoreGlobal
  - **Context parameter wiring**: ctx_ptr passed through translator
  - All infrastructure ready for full variable support

- ‚úÖ **External Function Integration** (COMPLETE!)
  - **External function declarations** in Cranelift module
  - **Symbol registration** with JITBuilder for runtime linking
  - **Function call generation** from LoadVar/StoreVar opcodes
  - **Hash-based variable names** for efficient lookups
  - **Variable name mapping** (hash ‚Üí name) in VMContext
  - **End-to-end validation**: test_execute_with_variables passes!
  - Variables successfully load/store from JIT compiled code

- ‚úÖ **Testing & Benchmarking** (COMPLETE)
  - **12 comprehensive JIT tests** including variable execution
  - test_execute_with_variables validates full variable support
  - Test loop compilation with control flow
  - **Benchmark suite validating performance**:
    - `examples/jit_simple_test.rs` - 28-37K speedup validated
    - `examples/jit_microbenchmark.rs` - Loop performance testing
    - `examples/jit_loop_test.ruff` - Hot loop demonstration
    - `examples/benchmark_jit.ruff` - Runtime benchmark

**Phase 3: ‚úÖ COMPLETE!**

All goals achieved:
- ‚úÖ JIT compilation infrastructure
- ‚úÖ Native code execution
- ‚úÖ Variable support with runtime calls
- ‚úÖ Control flow (loops, conditionals)
- ‚úÖ Performance validation (28-37K speedup)
- ‚úÖ Comprehensive testing (43 tests passing)

**Performance Achieved**: üéØ **28,000-37,000x faster** than bytecode VM for pure arithmetic (exceeds 5-10x target by 2,800-3,700x!)

**Files Added**:
- `src/jit.rs` - JIT compiler implementation (1000+ lines with full variable support)
- `examples/jit_loop_test.ruff` - JIT compilation test example
- `examples/jit_simple_test.rs` - Performance validation (28-37K speedup)
- `examples/jit_microbenchmark.rs` - Loop performance testing

**Testing**:
- 12 JIT-specific tests covering infrastructure, translation, compilation, execution, and variables
- test_execute_with_variables validates end-to-end variable support
- All 43 unit tests pass with JIT integration
- Performance benchmarks validate massive speedup
- Zero regressions

---

#### Phase 4: Advanced JIT Optimizations (2-3 weeks) - ‚è≥ PLANNED

**Objectives**: Squeeze out maximum performance with type specialization

- **Type Specialization**: Generate optimized code for common types
  ```ruff
  func add(a, b) { return a + b }
  
  # JIT generates specialized versions:
  add_int_int(a: i64, b: i64) -> i64    # Fast path for integers
  add_float_float(a: f64, b: f64) -> f64  # Fast path for floats
  add_generic(a: Value, b: Value) -> Value  # Fallback
  ```

- **Escape Analysis**: Allocate objects on stack when they don't escape
  ```ruff
  func process() {
      point := {x: 10, y: 20}  # Doesn't escape ‚Üí stack allocation
      return point.x + point.y  # Returns primitive, point dies
  }
  ```

- **Guard Insertion**: Optimize for common case, check assumptions
  ```ruff
  # Assume x is always Int, guard against other types
  if type(x) == Int {
      # Fast path: compiled native code
      result := x * 2
  } else {
      # Slow path: deoptimize to interpreter
      deoptimize_and_retry()
  }
  ```

- **Loop-Invariant Code Motion**: Move repeated calculations out of loops
  ```ruff
  for i in range(1000) {
      result := expensive_constant() * i  # Move expensive_constant() outside loop
  }
  ```

- **Method Inlining**: Inline small method calls
  ```ruff
  # Instead of call overhead:
  result := obj.get_value()
  
  # JIT inlines to:
  result := obj.field_value  # Direct field access
  ```

**Expected Additional Gain**: 2-3x faster, bringing total to **20-50x faster than tree-walking interpreter**

---

#### Phase 5: True Async Runtime Integration (2-3 weeks) - ‚è≥ PLANNED

**Status**: Not Started  
**Priority**: P2 (Medium) - Quality of life improvement, not blocking v1.0  
**Dependencies**: Phase 1-4 complete

**Why This Matters**:
Currently, async functions in the VM execute synchronously and wrap results in Promises. This works for most use cases but doesn't provide true concurrent I/O. Real-world applications need non-blocking async for:
- Concurrent HTTP requests
- Database connection pooling
- WebSocket servers
- File I/O without blocking
- Multi-client network services

**Objectives**: Integrate tokio runtime for true asynchronous execution

**Implementation Plan**:

- **Week 1: Tokio Integration**
  - Add `tokio` dependency to Cargo.toml
  - Create async runtime wrapper in VM
  - Implement spawn/join primitives for async tasks
  - Add async-aware event loop to VM execution
  
- **Week 2: Async Opcode Refactoring**
  - Refactor `Await` opcode to use tokio's await mechanism
  - Update `MakePromise` to create tokio futures
  - Implement async native functions (async_http_get, async_file_read, etc.)
  - Add task cancellation support
  
- **Week 3: Testing & Integration**
  - Update existing async tests to verify concurrent execution
  - Add concurrency tests (parallel HTTP requests, concurrent file I/O)
  - Benchmark I/O-bound workloads (should see significant improvements)
  - Update documentation with async best practices

**New Async Features**:
```ruff
# Concurrent HTTP requests (actually runs in parallel)
async func fetch_all(urls) {
    promises := urls.map(|url| async_http_get(url))
    results := await Promise.all(promises)  # Truly concurrent
    return results
}

# Background task spawning
task := spawn(async_long_running_operation())
# Do other work...
result := await task.join()

# Async timeout support
result := await timeout(fetch_data(), 5000)  # 5 second timeout
```

**Performance Benefits**:
- I/O-bound workloads: 10-100x faster (depends on concurrency level)
- CPU-bound workloads: No change (already fast with JIT)
- Real-world mixed workloads: 5-20x faster

**Alternative**: If tokio proves too heavy, consider `async-std` or custom lightweight runtime

---

#### Phase 6: Benchmarking & Tuning (1-2 weeks)

**Objectives**:
1. Validate performance improvements
2. Identify remaining bottlenecks
3. Compare against other languages

**Benchmark Suite**:
```bash
# Create comprehensive benchmarks
ruff benchmark --compare go,python,ruby,node

Benchmarks:
  - Fibonacci (recursion)
  - Array operations (map, filter, reduce)
  - HTTP server throughput
  - JSON parsing
  - String manipulation
  - Concurrent execution (async/await)
  - Mathematical computations
  - File I/O
  
Results:
  Ruff:   1000 req/sec  (baseline)
  Go:     2000 req/sec  (2.0x faster)
  Node:   900 req/sec   (0.9x faster)
  Python: 500 req/sec   (0.5x faster)
  Ruby:   400 req/sec   (0.4x faster)
```

**Profiling Tools**:
- CPU profiling (identify hot functions)
- Memory profiling (find allocations)
- JIT compilation statistics (hit rates)
- Instruction cache analysis

**Tuning**:
- Adjust JIT thresholds based on workload
- Optimize frequently-used built-in functions
- Reduce memory allocations in hot paths
- Improve instruction cache locality

---

## Implementation Strategy

**Integration with v0.9.0**:
- This work happens **during** v0.9.0 (parallel with modularization)
- Modularize interpreter.rs **first** (makes VM work easier)
- VM integration hPriority & Success Criteria

**Current Sprint** (Week 5-6):
1. üéØ Implement generator support in VM (Yield/Resume/MakeGenerator)
2. üéØ Implement async/await support in VM (Await/MakePromise)
3. üéØ Test generator and async VM implementations

**Next Sprint** (Week 7-8):
1. Switch default to VM mode (`--interpreter` for fallback)
2. Comprehensive testing (all 198+ tests in VM mode)
3. Performance benchmarking and documentation

**Overall Success Metrics**:
- All tests pass with VM as primary execution path
- Zero regressions in language features  
- Performance: 10-50x faster than tree-walking (Phase 1)
- Performance: 100-500x faster after JIT (Phases 2-4)

---

## v0.9.0 - Architecture Cleanup Tasks (P2)

These run in parallel with VM work and don't block v1.0:p<Arc<Vec<Stmt>>>);
```

**Root Cause**: Recursive drop implementations traverse deeply nested AST structures where `Stmt` contains more `Vec<Stmt>`.

**Proposed Solutions**:

1. **Iterative Drop Traversal** (Recommended)
   - Implement custom Drop using iteration instead of recursion
   - Use work queue to traverse AST nodes
   - Example pattern:
     ```rust
     impl Drop for FunctionBody {
         fn drop(&mut self) {
             let mut stack = vec![self.0.clone()];
             while let Some(node) = stack.pop() {
                 // Add child nodes to stack
                 // Drop happens when Arc count reaches 0
             }
         }
     }
     ```

2. **Arena Allocation**
   - Use `typed-arena` or similar crate
   - Allocate AST nodes in arena
   - Drop entire arena at once
   - Benefits: Faster allocation, no drop recursion
   - Trade-off: Different memory model

3. **Flatten Statement Structures**
   - Reduce nesting depth in AST
   - Use indices instead of nested Vec
   - More complex parsing, simpler runtime

**Impact**: Eliminates memory leaks, cleaner architecture, better long-term maintenance.

---

### 30. Separate AST from Runtime Values (P2)

**Status**: Planned  
**Estimated Effort**: Large (3-4 weeks)

**Problem**: Current mixing of compile-time AST and runtime values:
```rust
// AST node
pub enum Stmt {
    FuncDef { body: Vec<Stmt>, ... }
}

// Runtime value contains raw AST!
pub enum Value {
    Function(Vec<String>, LeakyFunctionBody, ...) // Contains Vec<Stmt>
}
```

**Proposed Separation**:
```rust
// AST stays pure (compile-time only)
pub enum Stmt { ... }

// Runtime uses compiled intermediate representation
pub enum Value {
    Function(Vec<String>, CompiledBody, ...)
}

struct CompiledBody {
    instructions: Vec<Instruction>, // IR or bytecode
    constants: Vec<Value>,
    locals_count: usize,
}
```

**Benefits**:
- Clear separation of compile-time vs runtime
- Enables optimization passes on IR
- No LeakyFunctionBody workaround needed
- Natural path to bytecode VM
- Faster function calls (pre-compiled)

**Implementation Phases**:
1. Define IR (intermediate representation) format
2. Add compilation pass: AST ‚Üí IR
3. Update interpreter to execute IR
4. Remove AST from runtime values
5. Optimize IR execution

---

### 31. Unified Type System Documentation (P2)

**Status**: Planned  
**Estimated Effort**: Small (3-5 days)

**Problem**: Unclear relationship between type constructs:
- `Value::Tagged` - enum variants with fields
- `Value::Struct` - runtime struct instances
- `Value::StructDef` - struct definitions with methods
- `Value::Enum` - exists but marked as dead code

**Deliverables**:

1. **Create `docs/type-system.md`**:
   - Philosophy: structural, nominal, or duck typing?
   - What types exist in Ruff?
   - How do Tagged, Struct, StructDef relate?
   - When to use each construct?
   - Examples of defining and using types
   - Type checking strategy (if any)

2. **Code Cleanup**:
   - Remove unused `Value::Enum` or implement it
   - Add documentation comments to type variants
   - Clarify naming (rename if needed)
   - Add examples in comments

3. **User Documentation**:
   - Add type system section to README
   - Document in language guide
   - Provide migration examples

---

### 32. Improve Error Context & Source Locations (P1)

**Status**: Planned  
**Estimated Effort**: Medium (2-3 weeks)

**Current Issues**:
- Line numbers incomplete throughout codebase
- Stack traces don't always show source locations
- Hard to trace runtime errors back to source code
- Error messages lack context

**Proposed Solution**:

1. **Add SourceLocation to AST Nodes**:
   ```rust
   pub struct SourceLocation {
       file: Rc<String>,
       line: usize,
       column: usize,
       length: usize,
   }
   
   pub struct Expr {
       kind: ExprKind,
       loc: SourceLocation,
   }
   
   pub struct Stmt {
       kind: StmtKind,
       loc: SourceLocation,
   }
   ```

2. **Maintain Call Stack**:
   ```rust
   pub struct CallFrame {
       function_name: String,
       location: SourceLocation,
   }
   
   pub struct Interpreter {
       call_stack: Vec<CallFrame>,
       // ... existing fields
   }
   ```

3. **Enhanced Error Messages**:
   ```rust
   Error at file.ruff:42:15
     40 | func calculate(x, y) {
     41 |     let result := x / y
     42 |     return result + z  // Error: undefined variable 'z'
        |                     ^
     43 | }
   
   Call stack:
     at calculate (file.ruff:42:15)
     at main (file.ruff:10:5)
   ```

4. **Error Chaining**:
   ```rust
   pub struct RuntimeError {
       message: String,
       location: SourceLocation,
       caused_by: Option<Box<RuntimeError>>,
   }
   ```

**Benefits**:
- Dramatically better debugging experience
- Easier to identify and fix errors
- Professional error reporting
- Better user experience

---

### 33. Trait-Based Value Operations (P2)

**Status**: Planned  
**Estimated Effort**: Medium (2-3 weeks)

**Problem**: Every operation on `Value` requires matching on 30+ variants, leading to massive code duplication.

**Current Pattern** (repeated hundreds of times):
```rust
match value {
    Value::Int(n) => { /* handle int */ }
    Value::Float(f) => { /* handle float */ }
    Value::Str(s) => { /* handle string */ }
    Value::Bool(b) => { /* handle bool */ }
    // ... 30+ more variants
    _ => Value::Error("unsupported type")
}
```

**Proposed Trait-Based Approach**:
```rust
pub trait ValueOps {
    fn add(&self, other: &Value) -> Result<Value, RuntimeError>;
    fn subtract(&self, other: &Value) -> Result<Value, RuntimeError>;
    fn multiply(&self, other: &Value) -> Result<Value, RuntimeError>;
    fn divide(&self, other: &Value) -> Result<Value, RuntimeError>;
    fn to_string(&self) -> String;
    fn to_bool(&self) -> bool;
    fn is_truthy(&self) -> bool;
    fn equals(&self, other: &Value) -> bool;
    fn compare(&self, other: &Value) -> Option<Ordering>;
}

impl ValueOps for Value {
    fn add(&self, other: &Value) -> Result<Value, RuntimeError> {
        match (self, other) {
            (Value::Int(a), Value::Int(b)) => Ok(Value::Int(a + b)),
            (Value::Float(a), Value::Float(b)) => Ok(Value::Float(a + b)),
            (Value::Str(a), Value::Str(b)) => Ok(Value::Str(format!("{}{}", a, b))),
            // ... centralized logic
            _ => Err(RuntimeError::type_error("Cannot add these types"))
        }
    }
    
    // ... other operations
}

// Usage in interpreter
let result = left_value.add(&right_value)?;
```

**Benefits**:
- Single source of truth for each operation
- Easier to add new operations
- Better testability (test traits independently)
- Reduced code duplication (~3000 lines saved)
- Easier to maintain type coercion rules
- Clear API surface

**Implementation Strategy**:
1. Define ValueOps trait with all operations
2. Implement trait for Value enum
3. Update interpreter to use trait methods
4. Remove duplicated match statements
5. Add comprehensive trait tests

---

### 34. Architecture Documentation (P1)

**Status**: Planned  
**Estimated Effort**: Small (1 week)

**Missing Documentation**:
1. **Architecture Overview**: How does the interpreter work?
2. **Contribution Guide**: How to add new features?
3. **Memory Model**: What's the ownership/borrowing story?
4. **Concurrency Model**: How do threads/async work?
5. **Extension API**: Can users add native functions?

**Deliverables**:

1. **`docs/ARCHITECTURE.md`**:
   - High-level system overview
   - Data flow: source ‚Üí tokens ‚Üí AST ‚Üí execution
   - Component responsibilities
   - Key design decisions and trade-offs
   - Diagrams (ASCII art or Mermaid)

2. **`CONTRIBUTING.md`**:
   - How to set up development environment
   - How to add a new built-in function
   - How to add a new language feature
   - Code style guidelines
   - Testing requirements
   - PR submission process

3. **`docs/CONCURRENCY.md`**:
   - Threading model (Arc<Mutex<>>)
   - Async/await architecture
   - Channel implementation
   - spawn block mechanics
   - Generator state management

4. **`docs/MEMORY.md`**:
   - Value ownership model
   - Environment lifetime management
   - Closure capture semantics
   - Garbage collection strategy (Arc/Drop)

5. **`docs/EXTENDING.md`**:
   - How to add native functions
   - How to create bindings to Rust libraries
   - Plugin system (if applicable)
   - FFI considerations

**Target Audience**:
- New contributors
- External developers integrating Ruff
- Future maintainers
- Security researchers

---

## ‚úÖ Recently Completed (v0.8.0 - v0.9.0)

**Modularization Complete**:
- ‚úÖ Interpreter modularization (14,802 ‚Üí 4,426 lines, 68.5% reduction)
- ‚úÖ Value enum extraction (500 lines ‚Üí value.rs)
- ‚úÖ Environment extraction (110 lines ‚Üí environment.rs)
- ‚úÖ Native functions modularization (13 category modules)

**VM Foundation**:
- ‚úÖ VM instruction set (60+ opcodes)
- ‚úÖ Bytecode compiler for all AST nodes
- ‚úÖ Exception handling in VM (BeginTry/EndTry/Throw/BeginCatch/EndCatch)
- ‚úÖ Native function integration (180+ built-in functions)
- ‚úÖ Closures and upvalue support

See [CHANGELOG.md](CHANGELOG.md) for complete details.

---

## v0.11.0 and Beyond

**Focus**: Complete stub modules and refine modular architecture  
**Timeline**: TBD (After v0.10.0)  
**Priority**: P2 (Medium) - Feature expansion as needed

> **Context**: Phase 3 (v0.9.0) successfully modularized native functions into 13 category modules. This release expands stub modules as features are needed and refines the module architecture based on real-world usage.

---

### 35. Complete Stub Native Function Modules (P2)

**Status**: Planned  
**Estimated Effort**: Medium per module (1-2 weeks each)

**Current Stub Modules** (return `None`, awaiting implementation):
- `json.rs` - JSON parsing and serialization
- `crypto.rs` - Encryption, hashing, digital signatures
- `database.rs` - MySQL, PostgreSQL, SQLite connections
- `network.rs` - TCP/UDP socket operations

**Implementation Strategy**: Implement modules **on-demand** based on user needs, not speculatively.

#### JSON Module (json.rs)

**Functions to Implement**:
```rust
// JSON parsing and serialization
parse_json(json_str: &str) -> Value
to_json(value: &Value) -> String
json_get(json: &Value, path: &str) -> Option<Value>  // JSONPath queries
json_merge(json1: &Value, json2: &Value) -> Value
```

**Trigger**: When users need JSON API integration or config file parsing.

**Estimated Effort**: 1 week

---

#### Crypto Module (crypto.rs)

**Functions to Implement**:
```rust
// Hashing
hash_md5(data: &str) -> String
hash_sha256(data: &str) -> String
hash_sha512(data: &str) -> String

// Encryption
aes_encrypt(data: &[u8], key: &[u8]) -> Vec<u8>
aes_decrypt(data: &[u8], key: &[u8]) -> Vec<u8>
rsa_encrypt(data: &[u8], public_key: &str) -> Vec<u8>
rsa_decrypt(data: &[u8], private_key: &str) -> Vec<u8>

// Digital signatures
rsa_sign(data: &[u8], private_key: &str) -> Vec<u8>
rsa_verify(data: &[u8], signature: &[u8], public_key: &str) -> bool
```

**Trigger**: When users need secure authentication or data encryption.

**Estimated Effort**: 2 weeks

---

#### Database Module (database.rs)

**Functions to Implement**:
```rust
// Connection management
db_connect(connection_string: &str) -> DatabaseConnection
db_close(conn: &DatabaseConnection)
db_pool_create(config: &Value) -> ConnectionPool

// Query execution
db_query(conn: &DatabaseConnection, sql: &str) -> Vec<Value>
db_execute(conn: &DatabaseConnection, sql: &str) -> i64  // Returns rows affected

// Transactions
db_begin_transaction(conn: &DatabaseConnection)
db_commit(conn: &DatabaseConnection)
db_rollback(conn: &DatabaseConnection)
```

**Trigger**: When users need persistent storage or database integration.

**Estimated Effort**: 2-3 weeks (complex due to connection pooling)

---

#### Network Module (network.rs)

**Functions to Implement**:
```rust
// TCP sockets
tcp_listen(addr: &str) -> TcpListener
tcp_accept(listener: &TcpListener) -> TcpStream
tcp_connect(addr: &str) -> TcpStream
tcp_read(stream: &TcpStream, bytes: usize) -> Vec<u8>
tcp_write(stream: &TcpStream, data: &[u8]) -> usize
tcp_close(stream: &TcpStream)

// UDP sockets
udp_bind(addr: &str) -> UdpSocket
udp_send_to(socket: &UdpSocket, data: &[u8], addr: &str) -> usize
udp_recv_from(socket: &UdpSocket, bytes: usize) -> (Vec<u8>, String)
```

**Trigger**: When users need low-level networking or custom protocols.

**Estimated Effort**: 2 weeks

---

### 36. Module Architecture Refinements (P3)

**Status**: Planned  
**Estimated Effort**: Small (3-5 days)

**Proposed Improvements**:

1. **Split Large Modules**: If `collections.rs` (815 lines) becomes unwieldy:
   ```
   native_functions/
   ‚îú‚îÄ‚îÄ collections/
   ‚îÇ   ‚îú‚îÄ‚îÄ mod.rs       (dispatcher)
   ‚îÇ   ‚îú‚îÄ‚îÄ arrays.rs    (~300 lines)
   ‚îÇ   ‚îú‚îÄ‚îÄ dicts.rs     (~250 lines)
   ‚îÇ   ‚îú‚îÄ‚îÄ sets.rs      (~150 lines)
   ‚îÇ   ‚îî‚îÄ‚îÄ queues.rs    (~115 lines)
   ```

2. **Add Module-Level Documentation**: Document category patterns:
   ```rust
   //! Collections module - Array, Dict, Set, Queue, Stack operations
   //!
   //! # Architecture
   //! - Returns `Option<Value>` (Some if handled, None to try next module)
   //! - Higher-order functions (map, filter, reduce) require `&mut Interpreter`
   //! - Polymorphic functions (len, contains) delegate via None returns
   //!
   //! # Performance
   //! - All operations are O(1) to O(n) where n is collection size
   //! - No heap allocations for primitive operations
   ```

3. **Performance Monitoring**: Add telemetry for dispatcher overhead:
   ```rust
   // In debug mode, track module hit rates
   #[cfg(debug_assertions)]
   fn log_dispatcher_stats() {
       // Which modules handle most calls?
       // Are there hot paths we can optimize?
   }
   ```

**Trigger**: Implement when module size or complexity becomes problematic.

---

## v0.10.0 - Optional Static Typing (Exploratory)

**Status**: Research & Design Phase  
**Timeline**: TBD (After v0.9.0 completion)  
**Priority**: Exploratory - Not committed for v1.0

> **Context**: Static typing could unlock significant performance improvements (approaching Go-level speed for typed code) while maintaining Ruff's dynamic nature. This is an exploratory investigation into gradual typing systems.

**Key Question**: Should Ruff adopt optional static typing like TypeScript, Python (type hints), or Dart?

---

### 35. Optional Type Annotations (Exploratory)

**Status**: Design Phase  
**Estimated Effort**: Medium (2-3 weeks for basic implementation)

**Motivation**:
- Enable 10-50x performance improvements for typed code paths
- Better IDE support (autocomplete, refactoring, go-to-definition)
- Catch bugs at compile time without sacrificing dynamism
- Competitive performance with Go for typed workloads

**Design Philosophy**: **Gradual Typing**
- Types are **optional**, not mandatory
- Dynamic code continues to work unchanged
- Types enable optimizations but don't change semantics
- Progressive enhancement: add types where they matter

---

#### Stage 1: Type Annotations (Documentation Only)

**Goal**: Add syntax for type annotations without runtime checking

**Syntax**:
```ruff
# Function parameter and return types
func calculate(x: int, y: float) -> float {
    return x * y
}

# Variable type annotations
let name: string := "Alice"
let age: int := 30
let scores: Array<int> := [95, 87, 92]

# Dict with typed keys/values
let user: Dict<string, any> := {
    "name": "Alice",
    "age": 30,
    "email": "alice@example.com"
}

# Optional types (nullable)
func find_user(id: int) -> User | null {
    if user_exists(id) {
        return fetch_user(id)
    }
    return null
}

# Union types
func process(value: int | string | bool) {
    # Handle multiple types
}

# Generic types (future)
func first<T>(arr: Array<T>) -> T | null {
    if len(arr) > 0 {
        return arr[0]
    }
    return null
}
```

**Implementation**:
1. Extend lexer for `:` and `->` type syntax
2. Parse type annotations in AST
3. Store type information (but don't enforce)
4. LSP can use for hover/autocomplete

**Benefits**:
- Documentation in code
- IDE tooling improvements
- Zero runtime cost
- Foundation for later stages

---

#### Stage 2: Optional Runtime Type Checking

**Goal**: Add opt-in runtime type validation

**Syntax**:
```ruff
# Enable type checking for specific function
@type_check
func calculate(x: int, y: float) -> float {
    return x * y  # Types validated at runtime
}

calculate(5, 3.14)       # ‚úÖ OK
calculate("5", 3.14)     # ‚ùå TypeError: expected int, got string

# File-level type checking
@strict_types

func add(a: int, b: int) -> int {
    return a + b
}

func greet(name: string) {
    print("Hello, ${name}!")
}

# All functions in file are type-checked
```

**Configuration**:
```toml
# ruff.toml
[type_checking]
mode = "optional"  # "off", "optional", "strict"
check_returns = true
check_parameters = true
allow_implicit_any = true
```

**Error Messages**:
```
TypeError at file.ruff:42:15
  Expected: int
  Got: string
  
  41 | func calculate(x: int, y: float) -> float {
  42 |     return x * y
       |            ^ type mismatch
  43 | }
  
  Hint: Ensure all parameters match their type annotations
```

**Benefits**:
- Catch bugs before production
- Validate API contracts
- Progressive type adoption
- Still allows dynamic code

---

#### Stage 3: JIT Optimization for Typed Code

**Goal**: Generate fast native code for type-annotated functions

**Performance Gains**:
```ruff
# Dynamic (current):
func sum_array(arr) {
    total := 0
    for n in arr {
        total := total + n
    }
    return total
}
# Performance: Baseline (100% time)

# Typed (optimized by JIT):
func sum_array(arr: Array<int>) -> int {
    total: int := 0
    for n: int in arr {
        total := total + n  # Direct CPU add, no boxing
    }
    return total
}
# Performance: 10-50x faster (2-10% of baseline time)
```

**JIT Optimizations Enabled by Types**:
1. **Unboxed arithmetic**: Direct CPU operations instead of Value enum
2. **Inline caching**: Skip type checks after first call
3. **Specialized code paths**: Generate int-specific, float-specific versions
4. **Stack allocation**: Allocate primitives on stack, not heap
5. **SIMD vectorization**: Process arrays in parallel with vector instructions

**Performance Comparison**:

| Code | Speed vs Go | Speed vs Dynamic Ruff |
|------|-------------|----------------------|
| Dynamic Ruff | 2-10x slower | 1x (baseline) |
| Typed Ruff (JIT) | 1-2x slower | 10-50x faster |
| Go | 1x (baseline) | 10-50x faster |

**Example - Real-World Impact**:
```ruff
# JSON parsing benchmark
func parse_json_dynamic(text: string) {
    # Current implementation: ~500 req/sec
}

func parse_json_typed(text: string) -> Dict<string, any> {
    # With types + JIT: ~2000 req/sec (4x faster)
}

# Go equivalent: ~3000 req/sec (1.5x faster than typed Ruff)
```

---

### Design Decisions to Explore

**1. Type Inference**
- Should `x := 5` infer `x: int`?
- How much inference vs explicit annotations?
- Balance between convenience and clarity

**2. Structural vs Nominal Typing**
```ruff
# Structural (like TypeScript):
type Point := { x: int, y: int }
let p := { x: 10, y: 20 }  # Matches Point automatically

# Nominal (like Java):
struct Point { x: int, y: int }
let p := Point { x: 10, y: 20 }  # Must explicitly construct
```

**3. Type System Complexity**
- Generics (Array<T>, Dict<K, V>)?
- Union types (int | string)?
- Intersection types?
- Dependent types?

**4. Gradual Typing Semantics**
- What happens at dynamic/typed boundary?
- Runtime casts vs compile-time errors?
- Performance implications of type guards?

**5. Compatibility**
- Can typed and untyped code interoperate seamlessly?
- What's the migration story for existing code?
- Breaking changes acceptable?

---

### Research Questions

**Before committing to implementation**:

1. ‚úÖ Performance analysis: Will types actually enable 10x+ speedups?
2. ‚úÖ User research: Do Ruff users want types?
3. ‚úÖ Ecosystem survey: How do Python, PHP, Ruby handle gradual typing?
4. ‚úÖ Complexity cost: Does type system add too much language complexity?
5. ‚úÖ Tooling requirements: What LSP/compiler changes are needed?
6. ‚úÖ Backward compatibility: Can we add types without breaking existing code?

**Prototype Goals**:
- Implement Stage 1 (annotations only)
- Test with real-world Ruff codebases
- Measure developer ergonomics
- Decide: proceed to Stage 2/3 or abandon

---

### Success Criteria (If Pursued)

**User Experience**:
- ‚úÖ Types feel natural, not bolted-on
- ‚úÖ Dynamic code still simple and pleasant
- ‚úÖ Migration path is gradual, not disruptive
- ‚úÖ Error messages are helpful, not cryptic

**Performance**:
- ‚úÖ Typed code approaches Go performance (1-2x slower)
- ‚úÖ Zero overhead for untyped code
- ‚úÖ JIT compilation success rate > 90%

**Tooling**:
- ‚úÖ VS Code autocomplete works well
- ‚úÖ Type errors caught by LSP before runtime
- ‚úÖ Refactoring tools leverage type information

**Ecosystem**:
- ‚úÖ Standard library has type annotations
- ‚úÖ Third-party packages adopt types
- ‚úÖ Documentation generator uses type info

---

### Timeline (If Approved)

| Version | Milestone | Effort |
|---------|-----------|--------|
| v0.10.0 | Stage 1: Type annotations (parser only) | 2-3 weeks |
| v0.11.0 | Stage 2: Runtime type checking | 3-4 weeks |
| v0.12.0 | Stage 3: JIT optimization for typed code | 4-6 weeks |

**Total**: 2-3 months of work **if** research validates the approach.

**Status**: üî¨ **EXPLORATORY** - Not yet approved for v1.0 roadmap.

---

## v0.11.0 - Developer Experience

**Focus**: World-class tooling for productivity  
**Timeline**: Q3 2026 (3 months)  
**See**: [PATH_TO_PRODUCTION.md](PATH_TO_PRODUCTION.md) Pillar 4


### 28. REPL Improvements (P2)

**Status**: Planned  
**Estimated Effort**: Medium (1-2 weeks)

**Current Gaps**:
- ‚ùå No tab completion
- ‚ùå No syntax highlighting
- ‚ùå No multi-line editing help
- ‚ùå No import from previous sessions
- ‚ùå No `.help <function>` documentation

**Features**:
```
$ ruff repl
>>> range<TAB>
range(stop)  range(start, stop)  range(start, stop, step)

>>> .help range
range(stop) - Generate sequence from 0 to stop-1
range(start, stop) - Generate sequence from start to stop-1  
range(start, stop, step) - Generate sequence with custom step

Examples:
  range(5) ‚Üí [0, 1, 2, 3, 4]
  range(1, 10, 2) ‚Üí [1, 3, 5, 7, 9]

>>> arr := [1, 2, 3]
[1, 2, 3]

>>> # Syntax highlighting for code
>>> func double(x) {
...     return x * 2
... }
<function double>

>>> .history
1: arr := [1, 2, 3]
2: func double(x) { return x * 2 }

>>> .save session.ruff  # Save session to file
```

**Implementation**: Enhanced rustyline integration, documentation database, completion provider

---

### 29. Documentation Generator (P2)

**Status**: Planned  
**Estimated Effort**: Medium (2-3 weeks)

**Features**:
```ruff
/// Calculates the square of a number.
/// 
/// # Examples
/// ```ruff
/// result := square(5)  # 25
/// result := square(10) # 100
/// ```
/// 
/// # Parameters
/// - n: The number to square (int or float)
/// 
/// # Returns
/// The square of the input (same type as input)
/// 
/// # Errors
/// None - this function cannot fail
func square(n) {
    return n * n
}
```

**CLI**:
```bash
ruff doc                    # Generate docs to ./docs
ruff doc --output ./api     # Custom output dir
ruff doc --serve            # Live preview on localhost:8080
ruff doc --format markdown  # or html, json
```

**Output**: Beautiful HTML documentation like Rust's docs.rs

---

### 30. Language Server Protocol (LSP) (P1)

**Status**: Planned  
**Estimated Effort**: Large (4-6 weeks)

**Why Critical**: Professional IDE support is non-negotiable for developer adoption

**Features**:
- **Autocomplete**: Built-ins, variables, functions, imports, struct fields
- **Go to definition**: Jump to function/struct/variable definitions
- **Find references**: Show all usages of a symbol
- **Hover documentation**: Show function signatures and doc comments
- **Real-time diagnostics**: Errors and warnings as you type
- **Rename refactoring**: Rename symbols across entire project
- **Code actions**: Quick fixes, import organization, extract function
- **Inlay hints**: Show inferred types and parameter names
- **Semantic highlighting**: Context-aware syntax coloring
- **Workspace symbols**: Jump to any symbol in project
- **IDE support**: VS Code (primary), IntelliJ, Vim, Emacs, Sublime

**Implementation**: Use `tower-lsp` Rust framework

---

### 31. Code Formatter (ruff-fmt) (P1)

**Status**: Planned  
**Estimated Effort**: Medium (2-3 weeks)

**Features**:
```bash
$ ruff fmt myproject/
Formatted 47 files in 1.2s
```

- Opinionated formatting (like gofmt, black, prettier)
- Configurable indentation
- Line length limits
- Import sorting

---

### 32. Linter (ruff-lint) (P1)

**Status**: Planned  
**Estimated Effort**: Medium (3-4 weeks)

**Rules**:
- Unused variables
- Unreachable code
- Type mismatches
- Suspicious comparisons
- Missing error handling
- Auto-fix for simple issues

---

### 33. Package Manager (P1)

**Status**: Planned  
**Estimated Effort**: Large (8-12 weeks)

**Why Critical**: No language succeeds without a package ecosystem

**Features**:
- `ruff.toml` project configuration
- Dependency management with semver
- Package registry (like npm, crates.io)
- CLI commands: `ruff init`, `ruff add`, `ruff install`, `ruff publish`, `ruff remove`
- Lock files for reproducible builds
- Private registry support
- Workspace support (monorepos)

**Example ruff.toml**:
```toml
[package]
name = "my-web-app"
version = "1.0.0"
authors = ["Alice <alice@example.com>"]
license = "MIT"

[dependencies]
http-server = "0.5.0"
json-schema = "1.2.0"
logger = "^2.0"  # Caret for compatible versions

[dev-dependencies]
test-utils = "0.1.0"

[scripts]
start = "ruff run server.ruff"
test = "ruff test tests/"
build = "ruff build --release"
```

---

### 34. Debugger (P2)

**Status**: Planned  
**Estimated Effort**: Medium (3-4 weeks)

**Features**:
```bash
$ ruff debug script.ruff
> break 25        # Set breakpoint
> run            # Start execution
> step           # Step into
> print x        # Inspect variable
> continue       # Continue to next breakpoint
```

---

### 35. Profiler (P2)

**Status**: Planned  
**Estimated Effort**: Medium (2-3 weeks)

**Features**:
```bash
$ ruff profile --cpu myapp.ruff
Top 10 functions by CPU time:
  43.2%  process_data    (1240ms)
  21.5%  http_get        (630ms)
  
$ ruff profile --memory myapp.ruff
Memory allocations:
  12.5 MB  Array allocations
   8.3 MB  Dict allocations
```

---

### 36. Hot Reload (P2)

**Status**: Planned  
**Estimated Effort**: Medium (2-3 weeks)

**Why Important**: Rapid development feedback loop

**Features**:
```bash
# Watch mode for development
ruff watch server.ruff          # Auto-restart on changes
ruff watch --exec "test"        # Run tests on changes
ruff watch --debounce 500       # Wait 500ms after last change
```

**Implementation**: File watcher + process management

---

### 37. Standard Patterns Library (P2)

**Status**: Planned  
**Estimated Effort**: Medium (2-3 weeks)

**Why Important**: Common patterns as built-in utilities save developers time

**Features**:
```ruff
import patterns

# Retry with exponential backoff
result := patterns.retry(
    func() { return http_get("flaky-api.com") },
    max_attempts=5,
    backoff="exponential",  # or "linear", "constant"
    initial_delay=100  # milliseconds
)

# Rate limiting
limiter := patterns.rate_limit(100, "per_minute")  # 100 calls per minute
for request in requests {
    limiter.wait()  # Blocks if rate exceeded
    process(request)
}

# Circuit breaker (prevent cascading failures)
breaker := patterns.circuit_breaker(
    failure_threshold=5,    # Open after 5 failures
    timeout=60,             # Try again after 60 seconds
    success_threshold=2     # Close after 2 successes
)

result := breaker.call(func() { 
    return external_api_call() 
})

if breaker.is_open() {
    print("Service degraded, using fallback")
}

# Memoization/caching
cached_fn := patterns.memoize(expensive_function)
result1 := cached_fn(10)  # Computed
result2 := cached_fn(10)  # Cached (instant)

# Debounce/throttle
throttled := patterns.throttle(api_call, 1000)  # Max once per second
debounced := patterns.debounce(search, 300)     # Wait 300ms after last call
```

---

### 38. HTTP Testing & Mocking (P2)

**Status**: Planned  
**Estimated Effort**: Small (1 week)

**Why Important**: Essential for testing HTTP-dependent code

**Features**:
```ruff
import http.testing

# Create mock server
mock := http_mock()
mock.on_get("/users", {
    status: 200, 
    body: [{"id": 1, "name": "Alice"}]
})
mock.on_post("/users", func(request) {
    # Dynamic response based on request
    return {status: 201, body: {"id": 2}}
})

# Use mock in tests
test "user service fetches users" {
    result := http_get("http://mock/users")
    assert_equal(result.status, 200)
    assert_equal(len(result.body), 1)
}

# Request assertions
mock.assert_called("/users", times=3)
mock.assert_called_with("/users", method="GET", headers={"Auth": "Bearer token"})

# Record/replay
recorder := http_recorder()
recorder.record(func() {
    http_get("real-api.com/data")
})
recorder.save("fixtures/api_response.json")

# Later, replay
replayer := http_replay("fixtures/api_response.json")
```

---

### 39. Language Server Protocol (LSP) (P1)

**Status**: Planned  
**Estimated Effort**: Large (4-6 weeks)

**Why Critical**: Professional IDE support is non-negotiable for developer adoption

**Features**:
- **Autocomplete**: Built-ins, variables, functions, imports, struct fields
- **Go to definition**: Jump to function/struct/variable definitions
- **Find references**: Show all usages of a symbol
- **Hover documentation**: Show function signatures and doc comments
- **Real-time diagnostics**: Errors and warnings as you type
- **Rename refactoring**: Rename symbols across entire project
- **Code actions**: Quick fixes, import organization, extract function
- **Inlay hints**: Show inferred types and parameter names
- **Semantic highlighting**: Context-aware syntax coloring
- **Workspace symbols**: Jump to any symbol in project
- **IDE support**: VS Code (primary), IntelliJ, Vim, Emacs, Sublime

**Implementation**: Use `tower-lsp` Rust framework

---

## v1.0.0 - Production Ready

**Focus**: Polish, documentation, community  
**Timeline**: Q4 2026 (3 months)  
**Goal**: Production-ready language competitive with other popular languages

**Milestones**:

**See**: [PATH_TO_PRODUCTION.md](PATH_TO_PRODUCTION.md) for complete v1.0 roadmap

---

## Future Versions (v1.0.0+)

### 27. Generic Types (P2)

**Status**: Research Phase  
**Estimated Effort**: Large (4-6 weeks)

**Planned Features**:
```ruff
# Generic functions
func first<T>(arr: Array<T>) -> Option<T> {
    if len(arr) > 0 {
        return Some(arr[0])
    }
    return None
}

# Ge30ric structs
struct Container<T> {
    value: T
    
    func get() -> T {
        return self.value
    }
}

# Type constraints
func process<T: Serializable>(item: T) {
    data := item.serialize()
}
```

---

### 28. Union Types (P2)

**Status**: Research Phase  
**Estimated Effort**: Medium (2-3 weeks)

**Fe31. Advancedres**:
```ruff
# Union type annotations
func process(value: int | string | null) {
    match type_of(value) {
        case "int": print("Number: ${value}")
        case "string": print("Text: ${value}")
        case "null": print("Empty")
    }
}

# Type aliases
type UserID = int
type Handler = func(Request) -> Response
```

---

### 29ures**:
```ruff
# sprintf-style formatting
format("Hello, %s!", ["World"])           # "Hello, World!"
format("Number: %d", [42])                # "Number: 42"
format("Float: %.2f", [3.14159])          # "Float: 3.14"
format("User %s scored %d points", ["Alice", 100])
```

**Implementation**: Add `format()` to `builtins.rs` with pattern matching

---

### 16. Assert & Debug (P2)

**Status**: Planned  
**Estimated Effort**: Small (2-3 hours)

**Features**:
```ruff
# Runtime assertions
assert(x > 0, "x must be positive")
assert_equal(actual, expected)

# Debug output
debug(complex_object)    # Pretty-printed output
```

**Implementation**: Add to `builtins.rs`, throw error on assertion failure

---

### 17. Range Function (P2)

**Status**: Planned  
**Estimated Effort**: Small (2-3 hours)

**Current Issue**: Examples use `range()` but it doesn't exist

**Features**:
```ruff
# Generate array of numbers
range(5)              # [0, 1, 2, 3, 4]
range(2, 8)           # [2, 3, 4, 5, 6, 7]
range(0, 10, 2)       # [0, 2, 4, 6, 8]

# Use in loops
for i in range(10) {
    print(i)
}
```

**Implementation**: Add `range()` to `builtins.rs`, return `Value::Array`

---

## v1.0.0+ - Advanced Features

### 40. Enums with Methods (P2)

**Status**: Planned  
**Estimated Effort**: Medium (2-3 weeks)

**Why Important**: Enums are more powerful when they have behavior

**Features**:
```ruff
enum Status {
    Pending,
    Active { user_id: int, started_at: int },
    Completed { result: string, finished_at: int },
    Failed { error: string }
    
    # Methods on enums!
    func is_done(self) {
        return match self {
            case Status::Completed: true
            case Status::Failed: true
            case _: false
        }
    }
    
    func get_message(self) {
        return match self {
            case Status::Pending: "Waiting to start..."
            case Status::Active{user_id}: "User ${user_id} is working"
            case Status::Completed{result}: "Done: ${result}"
            case Status::Failed{error}: "Error: ${error}"
        }
    }
}

# Usage
status := Status::Active { user_id: 123, started_at: now() }
print(status.get_message())  # "User 123 is working"
if status.is_done() {
    finalize()
}
```

---

### 41. Generic Types (P2)

**Status**: Research Phase  
**Estimated Effort**: Large (4-6 weeks)

**Planned Features**:
```ruff
# Generic functions
func first<T>(arr: Array<T>) -> Option<T> {
    if len(arr) > 0 {
        return Some(arr[0])
    }
    return None
}

# Generic structs
struct Container<T> {
    value: T
    
    func get(self) -> T {
        return self.value
    }
}

# Type constraints
func process<T: Serializable>(item: T) {
    data := item.serialize()
}

# Multiple type parameters
func zip<A, B>(arr1: Array<A>, arr2: Array<B>) -> Array<[A, B]> {
    result := []
    for i in range(min(len(arr1), len(arr2))) {
        result := push(result, [arr1[i], arr2[i]])
    }
    return result
}
```

---

### 42. Union Types (P2)

**Status**: Research Phase  
**Estimated Effort**: Medium (2-3 weeks)

**Features**:
```ruff
# Union type annotations
func process(value: int | string | null) {
    match type(value) {
        case "int": print("Number: ${value}")
        case "string": print("Text: ${value}")
        case "null": print("Empty")
    }
}

# Type aliases
type UserID = int
type Handler = func(Request) -> Response
type JSONValue = int | float | string | bool | null | Array<JSONValue> | Dict<string, JSONValue>
```

---

### 43. Macros & Metaprogramming (P3)

**Status**: Research Phase  
**Estimated Effort**: Large (3-4 weeks)

**Why Interesting**: Compile-time code generation enables DSLs and zero-cost abstractions

**Planned Features**:
```ruff
# Macro definitions
macro debug_print(expr) {
    print("${expr} = ${eval(expr)}")
}

# Usage
x := 42
debug_print!(x + 10)  # Output: "x + 10 = 52"
```

---

### 44. Foreign Function Interface (FFI) (P3)

**Status**: Research Phase  
**Estimated Effort**: Large (3-4 weeks)

**Description**:  
Call external C libraries and system functions from Ruff.

**Planned Features**:
```ruff
# Load C library
lib := load_library("libmath.so")

# Declare external function
extern func cos(x: float) -> float from lib

# Call C function from Ruff
result := cos(3.14159)
```

---

### 45. AI/ML Built-in (P3)

**Status**: Research Phase  
**Estimated Effort**: Very Large (2-3 months)

**Why Unique**: Differentiate Ruff as "AI-native" language - ML without heavy dependencies

**Planned Features**:
```ruff
import ml

# Simple linear regression
model := ml.linear_regression()
model.train(x_train, y_train)
predictions := model.predict(x_test)
mse := model.evaluate(x_test, y_test)

# Neural network (basic)
nn := ml.neural_net(
    layers=[784, 128, 64, 10],
    activation="relu",
    output_activation="softmax"
)

nn.train(
    x_train, 
    y_train, 
    epochs=10, 
    batch_size=32,
    learning_rate=0.001
)

accuracy := nn.evaluate(x_test, y_test)

# Common ML tasks
data := ml.normalize(raw_data)  # Feature scaling
[x_train, x_test, y_train, y_test] := ml.train_test_split(x, y, test_size=0.2)
confusion := ml.confusion_matrix(y_true, y_pred)

# Clustering
kmeans := ml.kmeans(n_clusters=3)
labels := kmeans.fit_predict(data)

# Decision trees
tree := ml.decision_tree(max_depth=5)
tree.train(x_train, y_train)
predictions := tree.predict(x_test)
```

**Implementation**: Embed lightweight ML library (maybe SmartCore or linfa for Rust)

---

### 46. Additional Compilation Targets (P3)

**Status**: Research Phase  
**Estimated Effort**: Very Large (1-2 months per target)

**Options** (after bytecode VM in v0.8.0):
1. **WebAssembly** - Compile to WASM for browser/embedded use
2. **Native Code** - AOT compilation to native executables via LLVM
3. **JIT Compilation** - Just-in-time compilation for hot paths (100x+ speedup)

---

### 47. Automatic Memory Management (P3)
**Status**: Research Phase  
**Estimated Effort**: Very Large (2-3 months)

**Description**:  
Automatic memory management with garbage collection or reference counting.

**Planned Features**:
- Automatic garbage collection
- Reference counting for immediate cleanup
- Cycle detection
- Memory profiling tools
- Leak detection and warnings

---

### 48. Graphics & GUI (P3)

**Status**: Research Phase  
**Estimated Effort**: Very Large (2-3 months)

**Description**:  
Graphics and GUI capabilities for visual applications.

**Terminal UI**:
```ruff
import tui

app := tui.App()
window := app.create_window(80, 24)

button := tui.Button {
    label: "Click Me",
    on_click: func() { print("Clicked!") }
}
window.add(button)
app.run()
```

**Canvas Drawing**:
```ruff
import graphics

canvas := graphics.Canvas(800, 600)
canvas.set_color(255, 0, 0)  # Red
canvas.draw_rect(100, 100, 200, 150)
canvas.draw_circle(400, 300, 50)
canvas.save("output.png")
```

---

### 49. WebAssembly Compilation (P3)

**Status**: Research Phase  
**Estimated Effort**: Very Large (2-3 months)

**Why Interesting**: Run Ruff in browsers, serverless, embedded systems

**Features**:
```bash
ruff build --target wasm script.ruff  # Compile to WASM
```

```html
<!-- Use in browser -->
<script type="module">
  import init, { run_ruff } from './script.wasm';
  await init();
  run_ruff();
</script>
```

---

## ü§ù Contributing

**Good First Issues** (v0.7.0):
- Timing functions (`current_timestamp`, `performance_now`)
- Type introspection (`type()`, `is_string()`, etc.)
- String formatting (`format()` function)
- Array utilities (`sort()`, `reverse()`, `unique()`)

**Medium Complexity** (v0.8.0):
- Destructuring
- Spread operator
- Enhanced error messages
- Standard library modules (arg parsing, compression, crypto)
- Result/Option types
- Bytecode instruction design

**Advanced Projects** (v0.9.0+):
- Async/await runtime
- Iterators & generators
- Language Server Protocol (LSP)
- Package manager & registry
- Code formatter and linter
- Debugger implementation
- Testing framework

---

## Version Strategy

**Current Approach**:
- **v0.6.0**: Production database support, HTTP streaming, collections ‚úÖ
- **v0.7.0**: Core language completion (foundation features + P2 quality-of-life) ‚úÖ
- **v0.8.0**: Performance (bytecode, 10x speedup) + modern syntax (destructuring, async)
- **v0.9.0**: Developer experience (LSP, package manager, tooling)
- **v1.0.0**: Production-ready, and competitive with other popular programming languages üéâ

**Philosophy**: Build the foundation first (language features), then performance, then tooling. This ensures LSP autocomplete and package manager are built on a complete, stable language.

**See Also**:
- [CHANGELOG.md](CHANGELOG.md) - Completed features and release history

---

## üìã Implementation Guidelines

### For Each New Feature:

1. **Plan** - Write specification with examples
2. **Test** - Create test cases before implementation
3. **Implement** - Update lexer, parser, AST, interpreter as needed
4. **Validate** - Ensure all tests pass, zero warnings
5. **Document** - Add examples and update README
6. **Release** - Update CHANGELOG with feature

### Code Quality Standards:


---

## ü§ù Contributing

Want to help implement these features? Check out [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

**Good First Issues** (v0.7.0):
- String padding methods (`pad_left`, `pad_right`)
- String case conversion (`to_camel_case`, `to_snake_case`, `slugify`)
- Array methods (`take`, `skip`, `chunk`, `enumerate`)

**Medium Complexity** (v0.8.0):
- Destructuring
- Spread operator  
- Enhanced error messages ("Did you mean?")
- Standard library modules (arg parsing, compression, crypto)
- Result/Option types
- Bytecode instruction design

**Advanced Projects** (v0.9.0+):
- Async/await runtime
- Iterators & generators
- Language Server Protocol (LSP)
- Package manager & registry
- Code formatter and linter
- Debugger implementation
- Testing framework

---

## Version Strategy

**Current Approach**:
- **v0.6.0**: Production database support, HTTP streaming, collections ‚úÖ
- **v0.7.0**: Core language completion (foundation features + P2 quality-of-life) ‚úÖ
- **v0.8.0**: Performance (bytecode, 10x speedup) + modern syntax (destructuring, async)
- **v0.9.0**: Developer experience (LSP, package manager, tooling)
- **v1.0.0**: Production-ready, Go/Python competitive üéâ

**Philosophy**: Build the foundation first (language features), then performance, then tooling. This ensures LSP autocomplete and package manager are built on a complete, stable language.

**See Also**:
- [CORE_FEATURES_NEEDED.md](CORE_FEATURES_NEEDED.md) - v0.7.0 implementation guide
- [PATH_TO_PRODUCTION.md](PATH_TO_PRODUCTION.md) - Complete roadmap to world-class language
- [CHANGELOG.md](CHANGELOG.md) - Completed features and release history

---

*Last Updated: January 25, 2026*
