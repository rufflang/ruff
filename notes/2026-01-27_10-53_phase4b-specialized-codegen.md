# Ruff Field Notes — Phase 4B: JIT Type-Specialized Code Generation

**Date:** 2026-01-27  
**Session:** 10:53 PST  
**Branch/Commit:** main / aac52b1  
**Scope:** Implemented Phase 4B specialized arithmetic code generation for JIT compiler. Added int-specialized fast paths for Add/Sub/Mul/Div operations with type-aware translation methods.

---

## What I Changed

- **Added 4 specialized translation methods** to `BytecodeTranslator` in `src/jit.rs`:
  - `translate_add_specialized(builder, var_a, var_b)` - Int-specialized addition
  - `translate_sub_specialized(builder, var_a, var_b)` - Int-specialized subtraction
  - `translate_mul_specialized(builder, var_a, var_b)` - Int-specialized multiplication
  - `translate_div_specialized(builder, var_a, var_b)` - Int-specialized division
- **Added helper method** `hash_var_name(name: &str) -> u64` for consistent variable type lookups
- **Added 5 new JIT tests** for specialized operations:
  - `test_int_specialized_addition`
  - `test_int_specialized_subtraction`
  - `test_int_specialized_multiplication`
  - `test_int_specialized_division`
  - `test_specialized_arithmetic_chain`
- **Updated documentation**:
  - `CHANGELOG.md` - Added Phase 4B section (75% complete)
  - `ROADMAP.md` - Updated Phase 4 progress to 75%
  - `README.md` - Added Phase 4 Advanced Optimizations section
- **Created 2 atomic commits**:
  1. `:package: NEW: Phase 4B specialized code generation infrastructure`
  2. `:book: DOC: update documentation for Phase 4B progress`

---

## Gotchas (Read This Next Time)

### Gotcha 1: Cranelift bitcast API is not what you think

- **Symptom:** Compilation error: `the trait bound 'MemFlags: From<cranelift::prelude::Value>' is not satisfied` and `this method takes 3 arguments but 2 arguments were supplied`
- **Root cause:** Tried to use `builder.ins().bitcast(types::F64, value)` for i64→f64 conversion. Cranelift's `bitcast()` requires 3 arguments (type, flags, value), not 2. Then tried `raw_bitcast()` which doesn't exist in this version of Cranelift.
- **Fix:** Deferred float specialization to Phase 4C. Focus Phase 4B on int-only specialization which uses native `iadd/isub/imul/sdiv` directly without type conversion.
- **Prevention:** 
  - Check Cranelift API docs before assuming type conversion methods
  - Float specialization requires proper understanding of Cranelift's type system
  - May need `fcvt_to_sint`, `fcvt_from_sint`, or memory-based reinterpretation
  - Document that i64⇄f64 bitcast is a separate research task

### Gotcha 2: Specialized methods need variable names, but bytecode is stack-based

- **Symptom:** Created specialized methods with signature `translate_add_specialized(builder, var_a: Option<&str>, var_b: Option<&str>)` but can't actually pass variable names from `translate_instruction`
- **Root cause:** Bytecode operates on a value stack without tracking provenance. When we pop two values for Add, we don't know which variables they came from.
- **Fix:** Phase 4B methods accept `Option<&str>` parameters but currently always receive `None`. The specialization lookup code is infrastructure for future work.
- **Prevention:**
  - To actually use type specialization, need to either:
    1. Track value provenance through SSA in Cranelift (complex)
    2. Specialize entire functions based on observed types (simpler)
    3. Insert type guards at function entry and assume types within
  - Phase 4D will likely implement approach #3 (guard at entry, assume within)
  - The current specialized methods check `self.specialization` context but don't get variable names from stack

### Gotcha 3: Specialized methods exist but aren't wired up yet

- **Symptom:** Created 4 specialized translation methods but they're never called from `translate_instruction`
- **Root cause:** Phase 4B was about creating the infrastructure, not integrating it. Integration is Phase 4C.
- **Fix:** This is intentional. Methods exist and are tested via direct compilation, but `translate_instruction` still uses generic `iadd/isub/imul/sdiv` paths.
- **Prevention:**
  - Phase 4C task: Modify `OpCode::Add/Sub/Mul/Div` cases in `translate_instruction` to check `self.specialization` and route to specialized methods
  - Need to decide: specialize at per-operation level (complex) or per-function level (simpler)
  - Document that Phase 4B is "methods exist" and Phase 4C is "methods used"

### Gotcha 4: Test compilation success ≠ execution validation

- **Symptom:** Tests validate `compiler.compile(&chunk, 0).is_ok()` but don't execute the compiled code or validate results
- **Root cause:** JIT execution infrastructure exists (`test_execute_compiled_code`, `test_execute_with_variables`) but new specialized tests only check compilation, not execution
- **Fix:** Accepted for Phase 4B. Compilation success proves IR generation works. Execution tests exist in Phase 3 tests.
- **Prevention:**
  - Phase 4C should add execution tests for specialized paths
  - Consider: benchmark comparing specialized vs. non-specialized execution times
  - Need execution harness that can call compiled functions with different type profiles

---

## Things I Learned

### Mental Model Updates

1. **Specialization happens at the function level, not operation level**
   - The `SpecializationInfo` in `JitCompiler` is keyed by bytecode offset (function entry)
   - A function gets one specialization profile, not per-operation
   - This makes sense: you profile a hot function's variables, then recompile the whole function with type assumptions

2. **Type guards go at function entry, not per-operation**
   - When you JIT compile with specialization, you insert guards at the START
   - If guards pass, entire function body assumes those types
   - If guards fail, deoptimize and recompile or fall back to interpreter
   - This is why `jit_check_type_int` and `jit_check_type_float` exist

3. **The specialized methods are templates for future function-level specialization**
   - They show HOW to generate type-specialized code
   - But the integration will be: "compile this function assuming x:Int, y:Int"
   - Not: "specialize this Add operation"

4. **Cranelift IR generation is two-phase: declare then generate**
   - Block creation happens first (all jump targets)
   - Then instruction emission with proper block sealing
   - Specialized methods fit into the emission phase
   - Guards would fit at function entry before first block

### Rules of Thumb

- **Rule:** Int-specialized ops are just native Cranelift ops (iadd/isub/imul/sdiv). Float-specialized ops need type conversion research.
- **Rule:** If a method takes `Option<&str>` for variable names but you can't provide them, you're probably thinking about specialization at the wrong level.
- **Rule:** Phase boundaries: 4A=infrastructure, 4B=methods, 4C=integration, 4D=guards, 4E=optimizations. Don't blur them.
- **Rule:** Test compilation separate from execution. Compilation proves IR generation; execution proves correctness.

### Implicit Invariants

- **Invariant:** `BytecodeTranslator.specialization` is `Some` only when compiling with a stable type profile (90%+ same type, 60+ samples)
- **Invariant:** Specialized methods can assume `self.specialization` contains type info, but currently can't look up stack value types
- **Invariant:** All specialized tests use `LoadConst` which creates typed values on stack, but LoadVar creates untyped Value::Int pointers
- **Invariant:** The JIT compiler's `type_profiles` HashMap grows indefinitely - no eviction policy for cold functions (potential memory leak)

---

## Debug Notes

### Initial Cranelift bitcast failure

**Failing compilation:**
```
error[E0277]: the trait bound `MemFlags: From<cranelift::prelude::Value>` is not satisfied
error[E0061]: this method takes 3 arguments but 2 arguments were supplied
```

**Repro steps:**
1. Add `let a_f = builder.ins().bitcast(types::F64, a);` in translate_add_specialized
2. Run `cargo build --lib`
3. See error about bitcast signature

**Breakpoints/investigation:**
- Searched codebase for existing bitcast usage: `grep -rn "bitcast" src/jit.rs` - none found
- Tried `raw_bitcast()` as alternative - method doesn't exist
- Checked Cranelift version in Cargo.toml - using cranelift-codegen and cranelift-jit

**Final diagnosis:**
- Cranelift's type conversion is more complex than assumed
- Need to research proper i64⇄f64 conversion in Cranelift
- Decision: Focus Phase 4B on int-only, defer float to Phase 4C
- This keeps Phase 4B scope manageable and shippable

---

## Follow-ups / TODO (For Future Agents)

- [ ] **Phase 4C:** Wire specialized methods into `translate_instruction` 
  - Check `self.specialization.is_some()` in Add/Sub/Mul/Div cases
  - Route to specialized methods when profile available
  - Fall back to generic ops when no profile

- [ ] **Phase 4D:** Implement guard generation at function entry
  - Use `jit_check_type_int` and `jit_check_type_float` helpers
  - Generate conditional branches: if guards pass → specialized path, else → deopt
  - Test guard success and failure cases

- [ ] **Float specialization research:**
  - Investigate correct Cranelift API for i64⇄f64 conversion
  - Options: bitcast with MemFlags, fcvt instructions, load/store through memory
  - Consider if float specialization is worth the complexity
  - Maybe focus on int-heavy workloads first

- [ ] **Execution benchmarks for Phase 4:**
  - Create benchmark comparing specialized vs. non-specialized function execution
  - Validate the expected 2-3x speedup claim
  - Test with: pure int arithmetic, mixed operations, variable-heavy code

- [ ] **Type profile memory management:**
  - Current: `type_profiles: HashMap<usize, SpecializationInfo>` grows unbounded
  - Risk: Memory leak if many functions executed once
  - Consider: LRU eviction, size limit, or profile reset after N compilations

- [ ] **Document the specialization mental model:**
  - Create architecture doc explaining function-level vs operation-level specialization
  - Clarify when guards are checked (entry) vs when types are assumed (body)
  - Explain why variable names aren't tracked on the stack

---

## Links / References

### Files touched:
- `src/jit.rs` - Added specialized methods and tests (lines 874-1000, 1630-1730)
- `CHANGELOG.md` - Phase 4B section
- `ROADMAP.md` - Phase 4 progress update
- `README.md` - Phase 4 summary

### Related docs:
- `.github/AGENT_INSTRUCTIONS.md` - Incremental commit guidelines
- `ROADMAP.md` Phase 4 section - Complete technical roadmap
- Cranelift documentation (external) - Type system and IR generation

### Key code sections:
- `BytecodeTranslator` struct (line 443) - Holds specialization context
- `translate_instruction()` method (line 535) - Where integration will happen
- `JitCompiler::type_profiles` (line 439) - Stores per-function type observations
- Runtime helpers (lines 206-419) - jit_load_variable_float, jit_check_type_*

### Test files:
- Lines 1510-1650 in `src/jit.rs` - Original Phase 3 tests
- Lines 1630-1730 in `src/jit.rs` - New Phase 4B specialized tests
- Total: 22 JIT tests, all passing

---

## Assumptions I Almost Made

1. **Almost assumed:** Cranelift bitcast would be simple like `bitcast(target_type, value)`
   - **Reality:** Cranelift's type conversion is architecture-specific and complex
   - **Learned:** Research APIs before assuming standard names work

2. **Almost assumed:** Specialized methods would be called immediately after creation
   - **Reality:** Phase 4B is infrastructure only; integration is Phase 4C
   - **Learned:** Clear phase boundaries prevent scope creep

3. **Almost assumed:** Tests need to execute compiled code to validate specialization
   - **Reality:** Compilation success validates IR generation; execution tests are separate
   - **Learned:** Test what you built in this phase, not what future phases will build

4. **Almost assumed:** Stack-based bytecode could provide variable names for type lookup
   - **Reality:** Stack values don't carry provenance metadata
   - **Learned:** Specialization will be function-level, not operation-level
